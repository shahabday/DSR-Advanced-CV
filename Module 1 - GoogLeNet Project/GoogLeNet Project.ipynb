{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qNR1BrMnqG8"
      },
      "source": [
        "# GoogLeNet for Cats and Dogs predictions\n",
        "\n",
        "<br>\n",
        "\n",
        "![](https://www.allaboutpetsprovo.com/wp-content/uploads/2019/09/cat-dog-exchange.jpg)\n",
        "<center>Image taken from <a href=\"https://www.allaboutpetsprovo.com/cats-vs-dogs.html\">here</a></center>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "In this lesson, you will build GoogLeNet neural network from **scratch** using the Keras (TensorFlow 2.+) library and train it to recognize images of cats and dogs. Let's start!\n",
        "\n",
        "### Steps:\n",
        "1. Import libraries and download the dataset\n",
        "2. Create an InceptionBlock\n",
        "3. Build the original GoogLeNet architecture\n",
        "4. Load data using tensorflow ImageDataGenerator\n",
        "5. Train the model\n",
        "\n",
        "### Topics covered and learning objectives\n",
        "- Load image data from folders using *ImageDataGenerators*\n",
        "- GoogLeNet model - Implementation and network architecture\n",
        "- Inception blocks\n",
        "- Build from scratch GoogLeNet model using Keras (TensorFlow) library\n",
        "\n",
        "### Time estimates:\n",
        "- Reading/Watching materials: 1h 45min\n",
        "- Exercises: 1h 10min\n",
        "<br><br>\n",
        "- **Total**: ~3h"
      ],
      "id": "7qNR1BrMnqG8"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lum7724unqG9"
      },
      "outputs": [],
      "source": [
        "from pathlib import PurePath, Path\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tests import *\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, Layer, MaxPool2D, GlobalAvgPool2D, Dense, AveragePooling2D, Flatten, Dropout, Input, Concatenate\n",
        "\n",
        "# For loading YouTube videos\n",
        "from IPython.display import IFrame"
      ],
      "id": "lum7724unqG9"
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the data from kaggele\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload kaggle.json\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jt8RXYsvn6Vs",
        "outputId": "ce36ac82-4e3b-4676-8d8d-7c4aa33ebc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "id": "jt8RXYsvn6Vs",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d85b3f57-d892-4a8d-aff5-f38ab0cb528f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d85b3f57-d892-4a8d-aff5-f38ab0cb528f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ac039f0f333f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will prompt you to upload kaggle.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/.kaggle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kaggle.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/root/.kaggle/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/.kaggle/kaggle.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set proper permissions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "shutil.move(\"kaggle.json\", \"/root/.kaggle/\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)  # Set proper permissions\n"
      ],
      "metadata": {
        "id": "qsZicWLnoHvv"
      },
      "id": "qsZicWLnoHvv",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats\n"
      ],
      "metadata": {
        "id": "FlQgxaonoNtJ",
        "outputId": "bf34d9b1-c9b7-41c4-a221-0cc3c4c0b195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FlQgxaonoNtJ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 793M/812M [00:06<00:00, 128MB/s]\n",
            "100% 812M/812M [00:06<00:00, 130MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('dogs-vs-cats.zip') as zip_ref:\n",
        "  zip_ref.extractall(\"dogsvscats\")\n",
        "\n",
        "  import zipfile\n",
        "path = 'dogsvscats'\n",
        "\n",
        "with zipfile.ZipFile(os.path.join(path ,\"train.zip\"), 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"train\")\n",
        "\n",
        "with zipfile.ZipFile(os.path.join(path,\"test1.zip\"), 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"test\")"
      ],
      "metadata": {
        "id": "I090wYlJoRkB"
      },
      "id": "I090wYlJoRkB",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ4zS24lnqG-"
      },
      "source": [
        "## Download the dataset\n",
        "\n",
        "Before starting the project, you'll need to download it from Kaggle and place it inside the **data**  folder created for you. [Download here](https://www.kaggle.com/c/dogs-vs-cats)\n",
        "\n",
        "For this exercise, we will use 2,000 images, which is only a subset of the entire dataset of 25,000 images.\n",
        "\n",
        "![](https://github.com/shahabday/DSR-Advanced-CV/blob/main/Module%201%20-%20GoogLeNet%20Project/images/download.png?raw=1)\n",
        "\n",
        "NOTE: Download might take a while! It is about 800 MBs\n",
        "\n",
        "Once downloaded, your zip file will contain **two (2)** zip files.\n",
        "\n",
        "Extract only these two files:\n",
        "- train.zip\n",
        "- test1.zip\n",
        "\n",
        "Extract both of them in the **data/module_1** folder inside the root directory of the repo for the following to work!\n",
        "\n",
        "After extracting everything, this was my folder structure:\n",
        "\n",
        "<pre>\n",
        "<b>module_1</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>test1</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>\n",
        "\n",
        "If everything is okay with this step, let's go and build the first part of our network, the InceptionBlock."
      ],
      "id": "YQ4zS24lnqG-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdNwe_kMnqG-"
      },
      "outputs": [],
      "source": [
        "# Dataset paths setup - used later in the code. You don't have to change anything here\n",
        "REPO_DIR = Path(os.getcwd()).parent\n",
        "\n",
        "# Note: Please put the data into the data folder in the root of the repo for the following to work!\n",
        "train_dir = REPO_DIR / \"data/module_1/train\"\n",
        "validation_dir = REPO_DIR / \"data/module_1/test1\""
      ],
      "id": "KdNwe_kMnqG-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co7iIGbynqG-"
      },
      "source": [
        "![Inception block](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-17-11-14-10.png)\n",
        "<center>Image taken from <a href=\"https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/\">here</a></center>\n",
        "\n",
        "<br><br>\n",
        "As seen on the image above, the Inception Block has 4 different parts which analyze an image (or input to the block) in different ways.\n",
        "\n",
        "Instead of having only one size representation of a layer input, Inception Block allows us to extract features from different image sizes, make our network more robust and ultimately more accurate.\n",
        "\n",
        "Okay, but what is the architecture?\n",
        "It's straightforward to build.\n",
        "\n",
        "#### 1st part\n",
        "- One conv layer with a kernel size of 1, ReLu activation\n",
        "\n",
        "#### 2nd part\n",
        "- First, conv layer with a kernel size of 1, ReLu activation\n",
        "- Second, conv layer with a kernel size of 3, ReLu activation and padding same\n",
        "\n",
        "#### 3rd part\n",
        "- First, conv layer with a kernel size of 1, ReLu activation\n",
        "- Second, conv layer with a kernel size of 5, ReLu activation and padding same\n",
        "\n",
        "#### 4rt part\n",
        "- First, MaxPool layer with a pool size of 3\n",
        "- Second, conv layer with a kernel size of 1, ReLu activation\n",
        "\n",
        "#### 5th part\n",
        "- Return the concatenation of all 4 channels using tf.concat\n",
        "\n",
        "Links to learn more about Inception blocks:\n",
        "\n",
        "Reading:\n",
        "- https://paperswithcode.com/method/inception-module\n",
        "- https://deepai.org/machine-learning-glossary-and-terms/inception-module"
      ],
      "id": "Co7iIGbynqG-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITzBRLKMnqG-",
        "outputId": "0f59092d-0796-4f54-c8a9-195c723b8180"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://www.youtube.com/embed/C86ZXvgpejM\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f505838a280>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IFrame(\"https://www.youtube.com/embed/C86ZXvgpejM\", 1000, 500)"
      ],
      "id": "ITzBRLKMnqG-"
    },
    {
      "cell_type": "markdown",
      "id": "290c3da6",
      "metadata": {
        "id": "290c3da6"
      },
      "source": [
        "**In some cases Ipython widgets do not work!**\n",
        "\n",
        "If this is the case here is the like for YouTube video from cell above: https://www.youtube.com/watch?v=C86ZXvgpejM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9659148",
      "metadata": {
        "id": "e9659148",
        "outputId": "d38a6bf9-5d2f-46cb-f5c9-39dd1c75ff0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"100%\" height=\"500\" src=\"https://www.youtube.com/embed/KfV8CJh7hE0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IFrame(\"https://www.youtube.com/embed/KfV8CJh7hE0\", 1000, 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnzcTkHInqG_"
      },
      "source": [
        "**In some cases Ipython widgets do not work!**\n",
        "\n",
        "If this is the case here is the like for YouTube video from cell above: https://www.youtube.com/embed/KfV8CJh7hE0"
      ],
      "id": "TnzcTkHInqG_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "0S5yDQuHnqG_",
        "outputId": "d1e50df6-d3dd-423d-eb8a-c33f4ca9b3a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"100%\" height=\"500\" src=\"https://www.youtube.com/embed/STTrebkhnIk\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IFrame(\"https://www.youtube.com/embed/STTrebkhnIk\", 1000, 500)"
      ],
      "id": "0S5yDQuHnqG_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPaGg6ZenqHA"
      },
      "source": [
        "**In some cases Ipython widgets do not work!**\n",
        "\n",
        "If this is the case here is the like for YouTube video from cell above: https://www.youtube.com/embed/STTrebkhnIk"
      ],
      "id": "WPaGg6ZenqHA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAk2nraxnqHA"
      },
      "source": [
        "## Exercise 1:\n",
        "\n",
        "Using the explanations and resources provided, complete the **InceptionBlock** function."
      ],
      "id": "lAk2nraxnqHA"
    },
    {
      "cell_type": "code",
      "source": [
        "def colored_string(s, color='black'):\n",
        "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
        "\n",
        "\n",
        "def TEST_INCEPTIONBLOCK(InceptionBlock):\n",
        "    input = Input(shape = (224, 224, 3))\n",
        "    if InceptionBlock(input, 10, (10, 10), (10, 10), 10).shape[1:] == [None, 224, 224, 40]:\n",
        "        return html_print(colored_string(\"IMPLEMENTATION IS CORRECT! GOOD JOB!\", 'green'))\n",
        "    else:\n",
        "        return html_print(colored_string(\"IMPLEMENTATION IS NOT CORRECT\", \"red\"))\n",
        "\n",
        "\n",
        "\n",
        "def TEST_AUXILARY(AuxilaryClassifier):\n",
        "    inputs = Input(shape = (10, 10, 1))\n",
        "    aux = AuxilaryClassifier(inputs)\n",
        "    model = Model(inputs=inputs, outputs=aux)\n",
        "    layers = model.layers\n",
        "\n",
        "    aux_test = True\n",
        "\n",
        "    if not model.count_params() == 526593:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"IMPLEMENTATION IS NOT CORRECT\", \"red\"))\n",
        "\n",
        "    if not type(layers[1]) == AveragePooling2D:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"FIRST LAYER SHOULD BE AveragePooling2D\", \"red\"))\n",
        "\n",
        "    if not type(layers[2]) == Conv2D:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"SECOND LAYER SHOULD BE Conv2D\", \"red\"))\n",
        "\n",
        "    if not type(layers[3]) == Flatten:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"THIRD LAYER SHOULD BE Flatten\", \"red\"))\n",
        "\n",
        "    if not type(layers[4]) == Dense:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"FOURTH LAYER SHOULD BE Dense\", \"red\"))\n",
        "\n",
        "    if not type(layers[5]) == Dropout:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"FIFTH LAYER SHOULD BE Dropout\", \"red\"))\n",
        "\n",
        "    if not type(layers[6]) == Dense:\n",
        "        aux_test = False\n",
        "        return html_print(colored_string(\"LAST LAYER SHOULD BE Dense\", \"red\"))\n",
        "\n",
        "    if aux_test:\n",
        "        return html_print(colored_string(\"IMPLEMENTATION IS CORRECT! GOOD JOB!\", 'green'))\n",
        "\n",
        "\n",
        "def TEST_GOOGLENET(model):\n",
        "\n",
        "    if not model.count_params() == 8471347:\n",
        "        return html_print(colored_string(\"IMPLEMENTATION IS NOT CORRECT, CHECK YOUR LAYERS AGAIN\", \"red\"))\n",
        "\n",
        "    if not len(model.outputs) == 3:\n",
        "        return html_print(colored_string(\"MAKE SURE THAT YOUR OUTPUTS HAVE 3 PARTS. 2 AUXILARY CLASSIFIERS AND FINAL OUTPUT\", \"red\"))\n",
        "\n",
        "    return html_print(colored_string(\"IMPLEMENTATION IS CORRECT! GOOD JOB!\", 'green'))"
      ],
      "metadata": {
        "id": "sPZbh2xCr2vo"
      },
      "id": "sPZbh2xCr2vo",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "sMgf-q6LnqHA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def InceptionBlock(inputs, filters_1, filters_2, filters_3, filters_4):\n",
        "    \"\"\"\n",
        "    Implement Inception block here\n",
        "\n",
        "    Args:\n",
        "        Inputs - previous layer from the network\n",
        "        filters_1 :int: - Number of filters used in the Part 1 of the Inception block. E.g. 32\n",
        "        filters_2 :Tuple: - Number of filters used for the two layers of the Part 2 E.g. (32, 32)\n",
        "        filters_3 :Tuple: - Nmber of filters used for the two layers of the Part 3 E.g. (32, 32)\n",
        "        filters_4 :int: - Number of filters used in the Part 4 of the Inception block E.g. 32\n",
        "\n",
        "    Return:\n",
        "        tf.concat - of all 4 parts\n",
        "    \"\"\"\n",
        "    #first branch\n",
        "    x1 = Conv2D(filters=filters_1, kernel_size = 1 , activation='relu')(inputs)\n",
        "\n",
        "    #second branch\n",
        "    x2 = Conv2D(filters=filters_2[0], kernel_size = 1 , activation='relu')(inputs)\n",
        "    x2 = Conv2D(filters=filters_2[1], kernel_size = 3 , activation='relu',padding='same')(x2)\n",
        "\n",
        "    #third branch\n",
        "    x3 = Conv2D(filters=filters_3[0], kernel_size = 1 , activation='relu')(inputs)\n",
        "    x3 = Conv2D(filters=filters_3[1], kernel_size = 5 , activation='relu',padding='same')(x3)\n",
        "\n",
        "    #fourth branch\n",
        "\n",
        "    x4 = MaxPool2D(pool_size=3 , padding= \"same\", strides=1\n",
        "                   )(inputs)\n",
        "    x4 = Conv2D(filters=filters_4, kernel_size = 1 , activation='relu')(x4)\n",
        "\n",
        "    print (x1.shape )\n",
        "    print(x2.shape)\n",
        "    print(x3.shape)\n",
        "    print(x4.shape)\n",
        "\n",
        "    output = Concatenate()([x1, x2,x3,x4])\n",
        "    #output = tf.concat([x1, x2,x3,x4] , axis=-1)\n",
        "    print(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n"
      ],
      "id": "sMgf-q6LnqHA"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ehNW89U2nqHA",
        "outputId": "dc968201-dd8a-4413-9930-491c8ae4ba62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 10)\n",
            "(None, 224, 224, 10)\n",
            "(None, 224, 224, 10)\n",
            "(None, 224, 224, 10)\n",
            "<KerasTensor shape=(None, 224, 224, 40), dtype=float32, sparse=False, name=keras_tensor_167>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:red>IMPLEMENTATION IS NOT CORRECT</text>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "\n",
        "# RUN THIS CELL TO CHECK IF YOUR SOLUTION IS CORRECT\n",
        "TEST_INCEPTIONBLOCK(InceptionBlock)"
      ],
      "id": "ehNW89U2nqHA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ3PDraqnqHA"
      },
      "source": [
        "# GoogleLeNet\n",
        "\n",
        "### Implementing GoogLeNet from scratch\n",
        "\n",
        "Like all big and famous architectures, GoogLeNet was created for the ImageNet competition. This architecture was later used to develop SOTA Face recognition applications, Reverse Image search, and many other Google products.\n",
        "\n",
        "What is so special about this model?\n",
        "\n",
        "GoogLeNet was created to solve the overfitting problem of big architectures. This was achieved by using Inception modules (layers) instead of the regular ones. Besides this *trick*, the authors have added two **mini-networks** in the middle of the model. These mini-networks are called Auxiliary classifiers.\n",
        "\n",
        "Read this -> https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5\n",
        "\n",
        "### Auxiliary classifier\n",
        "\n",
        "Auxiliary classifiers are small networks used ONLY in the TRAINING time to prevent vanishing gradient problems for more extensive networks.\n",
        "\n",
        "These small networks have the same output layer as the primary (big) model, with the Softmax/Sigmoid function. Calculating loss from these points helps preserver gradients in lower layers in the model and update the training time better.\n",
        "\n",
        "Note: The number of outputs depends on the number of classes. Our task here is cats vs. dogs. Since this is the binary classification, we will use Sigmoid instead of Softmax with only 1 (one) neuron as the output.\n",
        "\n",
        "While this is awesome for the training process, it is useless for the inference time, so we would only keep the main model in the production.\n",
        "\n",
        "Links to learn more about Auxiliary classifiers:\n",
        "\n",
        "- https://towardsdatascience.com/deep-learning-googlenet-explained-de8861c82765\n",
        "\n",
        "![Auxiliary classifier](https://miro.medium.com/max/550/1*htr2D6tKh3JMS7Acy4BDTw.png)\n",
        "<center>Image taken from <a href=\"https://towardsdatascience.com/deep-learning-googlenet-explained-de8861c82765\">here</a></center>\n",
        "\n",
        "<br><br>\n",
        "\n",
        "The architecture of the Auxiliary Classifier is pretty simple.\n",
        "- Start with AveragePooling with a pool size of 5x5 and strides of 3\n",
        "- Put that through Conv layer with 128 feature maps, kernel size of 1, padding same, and activation relu\n",
        "- Flatten the output of the Conv layer\n",
        "- Use Dense layer with activation relu and 1024 units\n",
        "- Add dropout layer of 0.7 or 70% drop\n",
        "- Complete it with a Dense (output) layer with 1 unit for binary classification or with the same number as the number of classes for multi-class classification.  (Sigmoid or Softmax)\n",
        "\n",
        "### Exercise 2 Complete the Auxiliary Classifier function\n",
        "\n",
        "Using the explanation and links provided, complete the *AuxiliaryClassifier* function and run tests to check if your implementation is correct."
      ],
      "id": "BQ3PDraqnqHA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxTYNjNonqHA"
      },
      "outputs": [],
      "source": [
        "def AuxilaryClassifier(X):\n",
        "    \"\"\"\n",
        "    Implement Inception block here\n",
        "\n",
        "    Args:\n",
        "        X - previous layer from the network\n",
        "\n",
        "    Return:\n",
        "        Last layer of the Auxilary Classifier (Softmax/Sigmoid)\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    raise NotImplementedError"
      ],
      "id": "SxTYNjNonqHA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEHqbp0jnqHA",
        "outputId": "bd445576-5465-4447-b97a-67c42d1a4734"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<text style=color:green>IMPLEMENTATION IS CORRECT! GOOD JOB!</text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RUN THIS CELL TO CHECK IF YOUR IMPLEMENTATION IS CORRECT\n",
        "TEST_AUXILARY(AuxilaryClassifier)"
      ],
      "id": "uEHqbp0jnqHA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCC6OGkXnqHB"
      },
      "source": [
        "## GoogLeNet architecture\n",
        "\n",
        "![GoogleNet model](https://paperswithcode.com/media/methods/Screen_Shot_2020-06-22_at_3.28.59_PM.png)\n",
        "<center>Image taken from <a href=\"https://paperswithcode.com\">here</a></center>\n",
        "<br><br>\n",
        "Now that we have the most crucial components of the GoogleNet model (**InceptionBlock** and **AuxiliaryClassifier**), let's walk through the whole architecture and start by implementing it inside the **GoogLeNet function**.\n",
        "\n",
        "GoogLeNet implementation guide:\n",
        "\n",
        "1. Start by defining the Input layer. In the original paper, the model accepted (224, 224, 3) size, so let's keep that.\n",
        "2. Define the first part of the model that goes:\n",
        "    - Conv with 64 feature maps, Kernel size of 7 and strides of 2, padding=valid\n",
        "    - Followed by MaxPooling layer with pooling size of 3 and strides 2, padding = same\n",
        "    - Conv with 64 feature maps with a kernel size of 1\n",
        "    - Conv with 192 feature maps, kernel size of 3, and padding is the same\n",
        "    - Finish this part with MaxPooling with a kernel size of 3 and strides of 2\n",
        "    \n",
        "3.  This part is given to you as a reference in the GoogLeNet function\n",
        "4.  Define the first Auxiliary Classifier\n",
        "5.  Followed by 3 Inception Blocks\n",
        "    - 1st block: 160, (112, 224), (24, 64), 64\n",
        "    - 2nd block: 128, (128, 256), (24, 64), 64\n",
        "    - 3rd block: 112, (144, 288), (32, 64), 64\n",
        "6. Define the second Auxiliary Classifier\n",
        "7. Define the last part of the network\n",
        "    - Inception block with config: 256, (160, 320), (32, 128), 128\n",
        "    - MaxPooling layer with pooling size of 3, strides are 2, and padding is same\n",
        "    - Inception block: 256, (160, 320), (32, 128), 128\n",
        "    - Inception block: 384, (192, 384), (48, 128), 128\n",
        "    - Global Average pooling layer\n",
        "    - Complete the network with Dense layer with the number of units 1 (Dogs vs. cats), activation sigmoid, and name=\"output\"\n",
        "\n",
        "8. Define the model using keras Model, where inputs will be inputs defined from the 1st step, and the outputs will be a list of 3 things - Last layer of the model, auxiliary classifier 1 outputs, and auxiliary classifier 2 outputs\n",
        "\n",
        "Learn more about GoogLeNet:\n",
        "- https://towardsdatascience.com/deep-learning-googlenet-explained-de8861c82765\n",
        "- https://www.geeksforgeeks.org/understanding-googlenet-model-cnn-architecture/"
      ],
      "id": "uCC6OGkXnqHB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTqLJBtynqHB"
      },
      "outputs": [],
      "source": [
        "def GoogLeNet():\n",
        "\n",
        "    # input layer\n",
        "\n",
        "    # First part of the network\n",
        "\n",
        "    # THIS PART IS GIVEN TO YOU AS A REFERENCE\n",
        "    X = InceptionBlock(X, 64, (96, 128), (16, 32), 32)\n",
        "    X = InceptionBlock(X, 128, (128, 192), (32, 96), 64)\n",
        "    X = MaxPool2D(pool_size=3, strides=2)(X)\n",
        "    X = InceptionBlock(X, 192, (96, 208), (16, 48), 64)\n",
        "\n",
        "    # 1st Aux classifier\n",
        "\n",
        "    # Inception blocks\n",
        "\n",
        "    # 2nd aux classifier\n",
        "\n",
        "    # Last part of the network\n",
        "\n",
        "    # Define the model\n",
        "\n",
        "    return model"
      ],
      "id": "kTqLJBtynqHB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJfdvEvcnqHB"
      },
      "source": [
        "### Let's use your completed function GoogLeNet() and defined the model"
      ],
      "id": "BJfdvEvcnqHB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ch5uiLnqHB"
      },
      "outputs": [],
      "source": [
        "model = GoogLeNet()"
      ],
      "id": "O1ch5uiLnqHB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ROxovwk5nqHB",
        "outputId": "86daa3da-8793-4f4d-a8b7-fd8ea154d01f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<text style=color:green>IMPLEMENTATION IS CORRECT! GOOD JOB!</text>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RUN THIS CELL TO CHECK IF YOUR IMPLEMENTATION OF GOOGLENET IS CORRECT\n",
        "TEST_GOOGLENET(model)"
      ],
      "id": "ROxovwk5nqHB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqp-1KEPnqHB"
      },
      "source": [
        "### Compile the model"
      ],
      "id": "Aqp-1KEPnqHB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC3PDm2bnqHB"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],\n",
        "              loss_weights=[1, 0.3, 0.3],\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "id": "iC3PDm2bnqHB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EArlQ1BznqHB"
      },
      "source": [
        "### Setting up config (Hyperparams) for the model"
      ],
      "id": "EArlQ1BznqHB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg9EcvNnnqHC"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=(224, 224) # <- DO NOT CHANGE\n",
        "\n",
        "# Experiment with batch_size and epochs\n",
        "batch_size=32\n",
        "epochs=15"
      ],
      "id": "Qg9EcvNnnqHC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne_DpUqcnqHC"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "\n",
        "To help ourselves in loading and processing images, let's use **ImageDataGenerator** provided as a part of the TensorFlow library.\n",
        "\n",
        "To learn more about data generators and how to use them, read this blog:\n",
        "\n",
        "- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ],
      "id": "Ne_DpUqcnqHC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7goLKdWznqHC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# For this project we will use only scaling as the image preprocessing step (All pixels between 0-1)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "id": "7goLKdWznqHC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhMGvniMnqHC"
      },
      "source": [
        "### Running Data Generators over the downloaded dataset\n",
        "\n",
        "Using ImageDataGenerators allows us to load images in many ways. In our case, we have all images in the folder called **data**, and each class is its folder *[\"cat,\" \"dog\"]*. This is the perfect setup for the function called **flow_from_directory**!\n",
        "\n",
        "This function takes data from a specified folder and automatically detects the number of images, number of classes and loads them in the memory when the training starts. When defining the generator, you can specify a standardized image size to resize all loaded images to the specified size.\n",
        "\n",
        "Here is the link to learn more about *flow_from_directory*:\n",
        "- https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"
      ],
      "id": "fhMGvniMnqHC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujKsXrnsnqHC"
      },
      "outputs": [],
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=IMG_SIZE,  # All images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "id": "ujKsXrnsnqHC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrKGFZxFnqHC"
      },
      "source": [
        "### Exercise 4 Train the *model* using all the parameters, **train_generator** and **validation_generator**\n",
        "\n",
        "HINT: Here is the post that explains how to train a model using data generators: https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
      ],
      "id": "nrKGFZxFnqHC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qizld62nqHC"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "0Qizld62nqHC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JygyaH5PnqHC"
      },
      "source": [
        "### Using trained model to make predictions"
      ],
      "id": "JygyaH5PnqHC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUhVfWl6nqHC"
      },
      "outputs": [],
      "source": [
        "predictions = np.where(model.predict(validation_generator)[0] < 0.5, 0, 1)"
      ],
      "id": "LUhVfWl6nqHC"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}